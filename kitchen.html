<p>
The videos you see here showcase three different demos.
</p>

<p>
First, ARMAR-7, a humanoid robot from Karlsruhe Institute of Technology, can execute complex tasks, like delivering food items. It learns from human demonstrations and its own experience, and it responds to spoken language or gestures.
</p>

<p>
Second, the Mobile ALOHA robot is a platform for bimanual mobile manipulation with low-cost whole-body teleoperation. It does imitation learning from human demonstrations, which then allows it to autonomously complete tasks like rinsing a dirty pan using a kitchen faucet, or even sauteing and serving shrimp.
</p>

<p>
Finally, the UMI Universal Manipulation Interface project employs handheld grippers to enable portable, low-cost, and information-rich data collection. The collected data is used to learn policies that are hardware-agnostic and deployable across multiple robot platforms. The resulting robot policies zero-shot generalize to novel environments and objects.
</p>
